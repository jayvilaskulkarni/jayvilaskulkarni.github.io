[
  {
    "objectID": "projects/PRJcsewp58/index.html",
    "href": "projects/PRJcsewp58/index.html",
    "title": "Regressive income shocks during COVID-19: Evidence from India",
    "section": "",
    "text": "Abstract\nStudies based on the Consumer Pyramids Household Survey (CPHS) in India have shown that the impact of the Covid-19 lockdown on household incomes was progressive in nature– richer households suffered more. But several media reports as well as purposive surveys carried out during the pandemic suggest that the poor suffered more than the rich. We use nationally representative panel data for urban India from the official Periodic Labour Force Survey (PLFS) to show that households that were relatively richer prior to the start of the pandemic suffered relatively less during the lockdown compared to households that were poorer. That is, the shock was regressive in nature. We also confirm that, as per CPHS, richer households did indeed experience higher drops in income than poorer ones. But we show that this progressivity is much less than what prevailed prior to the pandemic. Thus the pandemic either disrupted ongoing progressive income changes or was outright regressive in its impacts.\n\nRead Online\n\n\n\nAuthors\nAmit Basole, Anand Shrivastava, Jay Kulkarni and Akshit Arora"
  },
  {
    "objectID": "projects/PRJugthesis/index.html",
    "href": "projects/PRJugthesis/index.html",
    "title": "India’s Pandemic Through the Lens of Consumption Expenditure- Capturing Welfare Effects",
    "section": "",
    "text": "You can access my undergraduate thesis manuscript and my presentation to defend my thesis on this page.\n\nThesis\n\n\n  \n  \n  \n    \n    \n      Unable to display PDF file. Download instead.\n    \n  \n\n\n\nPresentation\n\n\n  \n  \n  \n    \n    \n      Unable to display PDF file. Download instead."
  },
  {
    "objectID": "blog/Bl20240827data/index.html",
    "href": "blog/Bl20240827data/index.html",
    "title": "A guide to webscraping using python + selenium",
    "section": "",
    "text": "Surge in New Data Sources\nModern statistics used in research isn’t much different than what it was seventy years ago. Richer sources of data and exponentially better computational power, however, have changed the way we do research. Typical data used in social science research comes from official sources. In developing countries like India, the official data is often released with delays or is not measured at all. Private data firms have started filling this gap by providing richer and high-frequency data. In both cases, the data is structured- documentation on survey design, weighting, and variable description is available. The researcher has to simply download and clean this data to find insights.\nSome interesting non-traditional data sources have become feasible for research. Improved optical character recognition (OCR) softwares have made it easier to digitize historic physical records and convert them into modern spreadsheets. Usage of open-access granular satellite data has become popular because individual persons or governments cannot tamper with data collection, and it is collected at high frequencies.\nThen there is unstructured data. Think of product reviews on Amazon’s website. The website can process unformatted text from several reviews and generate a summary of sentiments and most relevant phrases. Political analysts and marketing folks use similar unstructured text data from social media platforms to analyse user sentiments on the topic of interest. Further, there is semi-structured data. This is data spread over several pages of a website. There is a pattern in which each page of this website stores information, but it can’t be downloaded directly (no API access either). You will then use webscraping techniques to create a structured spreadsheet out of this website’s content. The webscraping process is the topic of this blog.\n\n\nChoice of tools: Python with Selenium\nSelenium belongs to the web-developer’s toolkit, but is integral to the webscraping process where human inputs are required. Technically, scraping a webpage should be the following simple steps: go to the webpage, parse its contents, store the relevant elements (typically as a dataframe). However, you may not have the direct link (url) to the website. You have a mental algorithm instead: go to a site, input text in the search bar, click ‘search’, visit every link on the results page and store relevant elements. Everything that needed human inputs (clicking, typing text) can be automated using selenium, making it a powerful scraping tool.\nSelenium can be used with many programming languages. Python is the choice here because of large online support materials available, especially for webscraping projects.\n\nTechnical Prerequisites:\nTo proceed, make sure that a recent version of python3 is installed. Selenium uses a web-browser for the automation. This requires you to install a web-browser and the driver for it (version of the browser and the driver should be matching). For instance, I am using Google Chrome as the browser with ChromeDriver version ‘128.0.6613.119’. Lastly, ensure that ChromeDriver is located on your python environment.\n\n\n\nIntroduction to XPATH\nElements of a webpage can be uniquely identified using xpaths. The xpath points Selenium to the precise location on a webpage (a button, a search box, etc.). One way to familiarize yourself with these is to right-click on your webpage and select ‘inspect’. In the image below, I have opened a page with some information about a tender from the European Union. The ‘inspect’ option opens the whole page’s structure on the right side. You can then copy the xpath.\n\n\n\nFinding xpath using the inspect tool on your browser. Right-click on the element -&gt; Copy -&gt; Copy XPath.\n\n\nLet’s try to scrape information on the ‘Title’ (Section 5) from the webpage in the above image. The code chunk below makes use of the website url and the xpath that you just copied to scrape the element (Title) and store it in a dataframe.\n#### importing libraries\nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.common.exceptions import NoSuchElementException\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nurl = \"https://ted.europa.eu/en/notice/-/detail/732644-2022\"\ndriver = webdriver.Chrome()\n\nrows = []\ndriver.get(url)\nprint(url)\ndriver.implicitly_wait(5)\ntitle = driver.find_elements(By.XPATH, '//*[@id=\"notice\"]/div[35]/div[2]/div')[0].text\n        \nrow = {'url':url,\n        'title':title}\n    \nrows.append(row)\ndriver.close()  \n\n### Make into a dataframe\ndf = pd.DataFrame(data= rows)\ndf\nThe output should look like this:\n\nYou just scraped one element from a webpage and stored it as desired. This is the most basic use of the webscraping technique. Note, however, that the xpath copied is specific to the particular page. If you replace the url with this url, your code will scrape something else instead of the ‘Title’. So if you have a list of 100 urls corresponding to a 100 contracts from the website in the example, this code will certainly break. The way forward is to write generic xpaths in your code.\n\nGeneric XPATHS\nThis YouTube video is a must watch, to master writing generic xpaths. I found the following to be the most useful:\n\nunderstanding xpath syntax (tag, attribute)\nusing multiple logical conditions (and, or)\ngoing from child to parent; parent to child\nhandling cases when one xpath gives multiple outcomes\nuseful functions (contains, starts with, table, count, ignore cases)\n\nIf you can write generic xpaths, the most critical part of your webscraping learning has been accomplished. Next, we will deal with a more realistic scenario: you have a list of urls, and for every url you need to scrape an element.\n\n\n\nEfficient for loops\nFor loops are familiar territory for Python users. You will naturally use them to scrape from a list of urls. Let’s scrape a different element (number of tenders received) from a list of five urls.\n### Load libraries \nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom webdriver_manager.chrome import ChromeDriverManager\n\n### Scrape data from five urls\nurls = [\"http://ted.europa.eu/udl?uri=TED:NOTICE:278789-2019:TEXT:EN:HTML\",\n        \"http://ted.europa.eu/udl?uri=TED:NOTICE:238723-2018:TEXT:EN:HTML\",\n        \"http://ted.europa.eu/udl?uri=TED:NOTICE:409966-2019:TEXT:EN:HTML\",\n        \"http://ted.europa.eu/udl?uri=TED:NOTICE:419164-2018:TEXT:EN:HTML\",\n        \"http://ted.europa.eu/udl?uri=TED:NOTICE:008451-2018:TEXT:EN:HTML\"]\n\ndriver = webdriver.Chrome()\n\nrows = []\nfor url in urls:\n    try:\n        driver.get(url)\n        driver.implicitly_wait(5)\n        num_tenders = driver.find_elements(By.XPATH, \"//span[@data-labels-key='ted_label.2014_common|offers_received']/..\")[0].text\n        row = {'url':url,\n               'num_tenders':num_tenders.partition(\"Number of tenders received: \")[2].partition(\"\\n\")[0]}\n    \n        rows.append(row)\n    except:\n        try:\n            num_tenders = driver.find_elements(By.XPATH, \"//span[@data-labels-key='ted_label.2014_common|award_no_tenders']\")[0].text\n            row = {'url':url,\n                   'num_tenders':num_tenders}\n            rows.append(row)\n        except:\n            try:\n                num_tenders = driver.find_elements(By.XPATH, \"(//span[@class='timark bold']/..)[6]\")[0].text\n                row = {'url':url,\n                       'num_tenders':num_tenders.partition(\"6. Number of tenders received\")[2].partition(\"\\n\")[2]}\n                rows.append(row)\n            except:\n                print(url)\n                continue\n\ndriver.close()\n### Make into a dataframe \ndf = pd.DataFrame(data= rows)\ndf\nThe output will look as follows:\n\n\nTips for efficient for loops\n\nUse of ‘continue’:\n\nif there is an exception, continues the loop without breaking the code.\n\nUse of ‘print(url)’:\n\nwhen there is an exception and the loop moves on, it is good to see why it has moved on, and for which urls that is the case. This is helpful while debugging the code.\n\nUse of nested try/except conditions:\n\nSometimes one element can be accessed by different xpaths. If the first xpath doesn’t fetch the desired element for you, the subsequent xpaths will! And you will notice the need to add that second xpath only when you are printing and examining the urls where your code is raising an exception (and continuing).\n\nAdding an implicit/explicit wait condition:\n\nSometimes an exception error is raised simply because the page had not loaded and the code tried to extract the element. A wait condition solves this issue.\nYou don’t want to overload the server with requests. They are designed to deal with human speeds of webpage interaction. It’s better to put in a wait condition than have an annoyed IT person blocking your IP address.\n\n\n\n\n\nClicking buttons and Sending text inputs\nSometimes you need to click buttons and send text inputs. Below is generic code to type in your username and password, and then clicking the log-in button. You are proficient enough to include this in your for-loop, if needed.\n#### importing libraries \nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.wait import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import NoSuchElementException\nfrom webdriver_manager.chrome import ChromeDriverManager\n\ndriver = webdriver.Chrome()\nwait = WebDriverWait(driver, 1)\ndriver.get(\"https://your-url-here/\")\nwait.until(EC.element_to_be_clickable((By.XPATH, \"{enter-xpath-here}\"))).send_keys(\"username\")\nwait.until(EC.element_to_be_clickable((By.XPATH, \"{enter-xpath-here}\"))).send_keys(\"password\")\nwait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='user-submit']\"))).click()\n\n\nThat’s it!\nWhat I have shared here are some useful things I picked up along my webscraping journey. You may learn additional tricks and create workflows that better suit your webscraping task. For whatever this was worth, I hope you found it useful!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "A guide to webscraping using python + selenium\n\n\n\n\n\n\n\nData\n\n\nPython\n\n\nSelenium\n\n\nWebscraping\n\n\n\n\nI collate the most useful webscraping tricks from my workflow and present it as a beginner’s guide.\n\n\n\n\n\n\nSep 22, 2024\n\n\nJay Kulkarni\n\n\n\n\n\n\n  \n\n\n\n\nDiary of Raja Neel Ratan Halder\n\n\n\n\n\n\n\nHistorical fiction\n\n\n\n\nA short fictional piece on a day in the life of a nineteenth century Indian landlord, who visits Industrializing Britain for the first time.\n\n\n\n\n\n\nSep 29, 2023\n\n\nJay Kulkarni\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Regressive income shocks during COVID-19: Evidence from India\n\n\n\n\n\n\n\nIncome Distribution\n\n\nLockdown\n\n\nCOVID-19\n\n\nIndia\n\n\n\n\nWorking Paper coauthored with Amit Basole, Anand Shrivastava and Akshit Arora.\n\n\n\n\n\n\nAug 22, 2024\n\n\nJay Kulkarni\n\n\n\n\n\n\n  \n\n\n\n\nDid Inequality Fall or Rise During the COVID-19 Lockdown?\n\n\n\n\n\n\n\nInequality\n\n\nIncome\n\n\nCOVID-19\n\n\nIndia\n\n\nData Visualization\n\n\n\n\nPoster presentation of the project where I contributed as a research assistant (Centre for Sustainable Employment, Bengaluru).\n\n\n\n\n\n\nJan 13, 2023\n\n\nJay Kulkarni\n\n\n\n\n\n\n  \n\n\n\n\nIndia’s Pandemic Through the Lens of Consumption Expenditure- Capturing Welfare Effects\n\n\nUndergraduate Thesis\n\n\n\n\nConsumption\n\n\nCOVID-19\n\n\nWelfare\n\n\nIndia\n\n\n\n\nThis thesis uses the CMIE-CPHS to capture the welfare effects of the pandemic on consumption expenditure. It finds that poverty spiked around lockdown one, but reverted to its pre-pandemic levels in the months that followed. It contributes to the literature by establishing that the drop in discretionary spending, that is dominated by richer quantiles drove the higher drop in overall MPCE for the rich.\n\n\n\n\n\n\nMay 7, 2022\n\n\nJay Kulkarni\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jay Kulkarni",
    "section": "",
    "text": "I study economics at Bocconi University, Milan (MSc in Economic and Social Sciences), where I am also an ICRIOS Visiting Student.\nI cherish data-driven insights, and take interest in empirical economic research. Applied econometrics and Macroeconomic development are my areas of interest. I am also passionate about data visualization."
  },
  {
    "objectID": "index.html#brief",
    "href": "index.html#brief",
    "title": "Jay Kulkarni",
    "section": "",
    "text": "I study economics at Bocconi University, Milan (MSc in Economic and Social Sciences), where I am also an ICRIOS Visiting Student.\nI cherish data-driven insights, and take interest in empirical economic research. Applied econometrics and Macroeconomic development are my areas of interest. I am also passionate about data visualization."
  },
  {
    "objectID": "blog/Bl20230930diary/index.html",
    "href": "blog/Bl20230930diary/index.html",
    "title": "Diary of Raja Neel Ratan Halder",
    "section": "",
    "text": "18th September, 1821\nToday has been an eventful day. It has been almost six months since I waved my goodbyes to the coast of Calcutta, and I was delighted to step foot on land again. It is a familiar comforting feeling to step foot on ground confidently and not have the ground wobble. To me, the ports of Lancashire seemed perpetually jostling with schooners and large sailing ships. It is sizably larger than our Calcutta’s port. Soon after docking, I found myself feeling the contours of the road, headed towards Bolton in Mr. Chillingworth’s chauffeured carriage.\nMr. Chillingworth is no nobleman like me, yet, the wealth and respect he commands is admirable. Himself an owner of a large cotton mill and a coal factory, Chillingworth has seen quite an upward mobility in his own lifetime. There is something of a Midas’s touch to these English enterprises. Most businessmen I know here managed to procure the right capital and have never looked back. I can’t say the same of our bloody merchants of Calcutta.\nAs we approached Bolton, I noticed cleaner roads with pavements and lighting. There were a few, fairly large houses in this area, Mr. Chillingworth’s being one of them. The carriage passed his well-kept garden, and Mr. Chillingworth himself greeted me. His place was a fifth the size of our Rakshali estate, but quite well staffed and comfortable. I vividly recall sitting in his living room and looking around as Mr. Chillingworth sipped on his Darjeeling first flush. These Englishmen have taken a fancy for this mild flavoured hot water. Tea served in that exquisite china is not to my taste, it’s best left for the ladies. His large living room seemed almost claustrophobic because of the endless objects on display. In one corner of the room sat a royal piano. The mantel-piece and the room’s walls were ornately stuffed with small luxury objects and paintings from halfway around the globe.\nAfter a heavy lunch we left for Mr Chillingworth’s cotton mill. Almost everything I saw on the way stood in stark contrast with my travel thus far. The factory stood on the other side of the most inhuman and disgusting part of Bolton. It was unfortunate, yet insightful to see this dark side of England’s thriving business. As the densely populated inhabitation of Bolton approached within a kilometre’s reach, an unbearable stench hit my nostrils. It only got worse as we approached the industrial town. I saw young children playing in filth, amidst garbage. It was surprising to see that there was no one around to look after those children. Back in Rakshali we always find mothers or grandparents keeping a watch on them. The water supply, the sanitation, and the housing, all looked unbearable. I began imagining this town with its people living in it. Entire families seemed to live in damp one-roomed hovels, some at below ground levels. Looking at the open sewers, I thought to myself that the poor town-dwellers would never escape this stench.\nUndisturbed by the obnoxious assault on our senses, Mr. Chillingworth continued to read his newspaper. I made some gestures to point at the scenery outside, to which he gave me flat reply. “It’s these jerry-builders you see, Raja Neel Ratan. They hear the news of a mill springing up, and before you know it, there are these matchbox houses and lousy farm labourers in it. It’s all haphazard. Not an element of planning in this. You wouldn’t expect any better living conditions”, Mr. Chillingworth said. A minute later he remarked that had the workers lived healthier, they wouldn’t fall sick so often and not lose their jobs. The carriage driver mentioned in private that the water shortage in this town was bad. There was only one stand pipe that served water to several streets. The already fatigued workers apparently had to rise at night and wait in long queues to procure water. These observations made me think about why anyone would want to live in these horrific conditions and go for work. The poorest folks of Rakshali have land for subsistence, when all other means of income fail. Perhaps these English workers have nothing to fall-back upon, forcing them to stay in such towns to find work. Or perhaps the rise of enterprises like Mr. Chillingworth’s have been the driving force behind these socio-economic changes.\nAs we left the stench and the filth, Mr. Chillingworth’s mill inched closer. The factory premises were dotted with large grey buildings. There was dust flying everywhere. A large clock-tower loomed above all the other buildings. I soon realized that it wasn’t the machines that ran this place, it was time.\nThe mechanized sounds could be heard even before we entered the buildings. This thrilled me. As we walked into the premises Mr. Chillingworth stiffened up. I don’t know if there was fear in the air, but nobody looked up as we crossed the aisle. On second thoughts, the nature of the work was such that the workers couldn’t afford to waste time by looking around. Each had a small task, which they performed day-in and day-out. Mr. Chillingworth was careful to not let me spend too long at the shop floor, where the main action was. His factory had apparently procured new state-of-the-art machinery that made ginning and pressing five times more productive. This machinery was still a secret, and was kept in a separate room. But before going to his office, I saw something strange.\nThere was a large hall with much smaller machines that were being operated by women and children! No disrespect for the English society, but women working beside men, under the same roof is bizarre. These workers must be in dire states to make the women of their house work in such conditions. Further, the work done by the men was not dignified either. The poor artisan of Rakshali would rather starve, than do undignified, mechanical work to earn a living…\nPerched in my chair after a comfortable supper, I can only remark that today was rather eventful. I am eager, yet reserved to know what Mr. Chillingworth’s coal mines have in place for me tomorrow. That would be all for now.\n\nNote: I originally wrote this piece for the course 'Survey of World Economic History' at Azim Premji University.\n\n\n\n\n\nReferences\n\nDickens, Charles. 2012. Hard Times. Collins Classics.\n\n\nGhosh, Amitav. 2008. Sea of Poppies: A Novel. Macmillan.\n\n\nMarshall, Ian. n.d. “Passage East.” https://archive.nytimes.com/www.nytimes.com/books/first/m/marshall-east.html?\\_r=1.\n\n\nMaxtone-Graham, John, and Ian Marshall. 1998. Passage East. Howell Press.\n\n\nThompson, E. P. 2016. Making of the English Working Class. Open Road Media."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am presently a second year student pursuing the MSc in Economic and Social Sciences at Bocconi University. I am selected in the ICRIOS Visiting Students Program (2023-2024), where we are mentored and trained in empirical research methods. I have completed courses like advanced statistics, advanced mathematics, advanced macroeconomics, macroeconometrics, development economics, economic analysis of crime, population dynamics, and labour economics. My thesis with Prof. Arnstein Aassve aims to examine the relationship between social networks and cognitive functioning of the elderly in Europe. The thesis will point out the heterogenities by gender, region, age, and education.\n\n\n\nI completed my B.A. (Honours) in Economics from Azim Premji University (Bengaluru). I took courses in economic theory (such as Intermediate Microeconomics and Macroeconomics, Econometrics and Political Economy), quantitative tools (Linear Algebra, Statistics, and Computational Economics), and on research methods (Communicating Economics, and Academic Writing). I completed my Honours thesis under Professor Amit Basole. The thesis was an empirical project that analyzed the effect of COVID-19 on India’s consumption expenditure. I used a regression framework to tease-out peculiar trends in consumption-inequality. Working on the thesis, various data assignments, and term papers during this program motivated me to deepen my understanding of theory, economic tools and skills. I became passionate about data visualization in R and typesetting in LaTeX. I also enjoyed applied courses on ‘Climate Change Economics’ and ‘Labour Economics’, where I got a chance to use economic models on real data.\n\n\n\nI am a proud alum of Rishi Valley School, KFI (Madnapalle). The six years I spent at this residential school have greatly shaped me and my outlook towards life. Today I structure my days in a balanced way because of school, where we did physical training (running/strength/sports) in the morning and evening, took classes in the day, reflected on the asthachal hill and went for the study hour (prep) at night. RV taught me so much more. I got introduced to bird-watching by the renowned ornithologist Dr. V Shantaram. The current affairs club, carefully curated by then-director Radhika Herzberger encouraged us to dive deeper and seek explanations for major events of the time. Our teachers encouraged us to read widely- from fiction, to technical and philosophical texts. I learnt to express myself in new ways- through Gieve Patel’s poetry workshops, Sonali akka’s theater classes and by doing pottery, needlecraft and batik. I grew as a person through my journey in sports. I entered RV with little interest in sports, discovered and played basketball consistently over the years and I graduated from school as the basketball captain. The school was also frequently visited by alumni and great minds from diverse walks of life- their talks during assemblies inspired me and exposed me to new ideas."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "I am presently a second year student pursuing the MSc in Economic and Social Sciences at Bocconi University. I am selected in the ICRIOS Visiting Students Program (2023-2024), where we are mentored and trained in empirical research methods. I have completed courses like advanced statistics, advanced mathematics, advanced macroeconomics, macroeconometrics, development economics, economic analysis of crime, population dynamics, and labour economics. My thesis with Prof. Arnstein Aassve aims to examine the relationship between social networks and cognitive functioning of the elderly in Europe. The thesis will point out the heterogenities by gender, region, age, and education.\n\n\n\nI completed my B.A. (Honours) in Economics from Azim Premji University (Bengaluru). I took courses in economic theory (such as Intermediate Microeconomics and Macroeconomics, Econometrics and Political Economy), quantitative tools (Linear Algebra, Statistics, and Computational Economics), and on research methods (Communicating Economics, and Academic Writing). I completed my Honours thesis under Professor Amit Basole. The thesis was an empirical project that analyzed the effect of COVID-19 on India’s consumption expenditure. I used a regression framework to tease-out peculiar trends in consumption-inequality. Working on the thesis, various data assignments, and term papers during this program motivated me to deepen my understanding of theory, economic tools and skills. I became passionate about data visualization in R and typesetting in LaTeX. I also enjoyed applied courses on ‘Climate Change Economics’ and ‘Labour Economics’, where I got a chance to use economic models on real data.\n\n\n\nI am a proud alum of Rishi Valley School, KFI (Madnapalle). The six years I spent at this residential school have greatly shaped me and my outlook towards life. Today I structure my days in a balanced way because of school, where we did physical training (running/strength/sports) in the morning and evening, took classes in the day, reflected on the asthachal hill and went for the study hour (prep) at night. RV taught me so much more. I got introduced to bird-watching by the renowned ornithologist Dr. V Shantaram. The current affairs club, carefully curated by then-director Radhika Herzberger encouraged us to dive deeper and seek explanations for major events of the time. Our teachers encouraged us to read widely- from fiction, to technical and philosophical texts. I learnt to express myself in new ways- through Gieve Patel’s poetry workshops, Sonali akka’s theater classes and by doing pottery, needlecraft and batik. I grew as a person through my journey in sports. I entered RV with little interest in sports, discovered and played basketball consistently over the years and I graduated from school as the basketball captain. The school was also frequently visited by alumni and great minds from diverse walks of life- their talks during assemblies inspired me and exposed me to new ideas."
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About",
    "section": "Work Experience:",
    "text": "Work Experience:\n\nLEAP, Bocconi University\nI worked as a research assistant to Professor Andrea Guariso at the Laboratory for Effective Anti-Poverty Policies (LEAP) over the summer of 2023. I was selected in the LEAP Internship Program. A new skill I learnt was to do ‘fuzzy matching’ of data in Stata. I further used the ‘LEDA’ package in R, which was specifically designed to match ethnic data-sets in Africa (relevant for the project). Using the LEDA package made me understand the basics of Object Oriented Programming. I also learnt QGIS to handle spatial data and attended workshops on research methods for development economics.\n\n\nXKDR Forum\nI collaborated with XKDR Forum (Mumbai) as a quantitative researcher. I was involved in a project on measuring the effect of finance on household consumption management. We used a longitudinal micro-data from India for the project. I visualized data and ran regressions using R for the project. At XKDR, I learnt to document my work systematically and to create functions from scratch in R. Working here has motivated me to learn more about open-source systems and to master the command line (great for productivity!), which is used de-facto at the organization.\n\n\nCentre for Sustaiable Employment\nI worked as a research assistant to Professors Anand Shrivastava and Amit Basole at the Centre for Sustainable Employment (CSE) (Bengaluru). I worked on a project on income-inequality during the pandemic. Contrary to the existing literature, we found preliminary evidence that income-inequality did not drop during the COVID-19 period, and established a pre-trend of already falling income-inequality in India. During my stint at CSE, ️I mainly did exploratory data analysis using R on AWS. After regular presentations and rigorous verifications, we narrowed down on a narrative. This work was presented at the Annual Research Conclave (2023) at Azim Premji University. It is now out as a working paper (August 2024). See ‘Projects’ page for details.\n\n\nSeva Mandir\nI worked as a research intern at Seva Mandir (Udaipur) in the summer of 2021. I was tasked to evaluate the effectiveness of one of Seva Mandir’s Water, Sanitation and Hygiene (WASH) intervention. I successfully conducted a primary survey (n=50 households) and submitted a report of my findings to the organization. I learnt to design a coherent questionnaire with inputs from my pilot run. I executed the survey with help from a balsakhi, who was trusted by the respondents and helped with language translation. This field experience helped me connect development theory with ground realities and was full of political economy insights."
  },
  {
    "objectID": "projects/PRJcovidinequality/index.html",
    "href": "projects/PRJcovidinequality/index.html",
    "title": "Did Inequality Fall or Rise During the COVID-19 Lockdown?",
    "section": "",
    "text": "This work was presented at the Annual Research Conclave (2023) at Azim Premji University, Bengaluru. As a research assistant, I helped with documentation, data visualization, and with executing the regression analysis for the project.1"
  },
  {
    "objectID": "projects/PRJcovidinequality/index.html#footnotes",
    "href": "projects/PRJcovidinequality/index.html#footnotes",
    "title": "Did Inequality Fall or Rise During the COVID-19 Lockdown?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is unpublished work, only uploaded here to give the reader a better sense of my experience as a research assistant during this stint.↩︎"
  }
]